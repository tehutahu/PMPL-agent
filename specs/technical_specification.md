# PMPL ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ  æŠ€è¡“ä»•æ§˜æ›¸

## 1. ã‚·ã‚¹ãƒ†ãƒ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

### 1.1 å…¨ä½“ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

#### 1.1.1 è­°è«–ãƒ•ãƒ­ãƒ¼ãƒ€ã‚¤ã‚¢ã‚°ãƒ©ãƒ 

```mermaid
graph TD
    A[ãƒ¡ã‚¤ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒãƒ¼ã‚¿ãƒ¼] --> B[è­°è«–é–‹å§‹ãƒ»è«–ç‚¹æ•´ç†]
    B --> C[ãƒ•ã‚§ãƒ¼ã‚º1: åˆæœŸè¦‹è§£è¡¨æ˜]
    C --> D[ãƒ•ã‚§ãƒ¼ã‚º2: ç›¸äº’è­°è«– å‰åŠ]
    D --> E[ãƒ•ã‚§ãƒ¼ã‚º3: ç›¸äº’è­°è«– å¾ŒåŠ]
    E --> F[ãƒ•ã‚§ãƒ¼ã‚º4: åˆæ„å½¢æˆ]
    F --> G[ãƒ•ã‚§ãƒ¼ã‚º5: è­°è«–ç·ã¾ã¨ã‚]
    G --> H[Markdownãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ]
    
    subgraph "å¯¾è©±çš„è­°è«–ãƒ—ãƒ­ã‚»ã‚¹"
        I[åŸºæœ¬ãƒšãƒ«ã‚½ãƒŠ5å]
        I --> J[ITã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—PM]
        I --> K[ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚ºPM]
        I --> L[ãƒ†ãƒƒã‚¯ãƒªãƒ¼ãƒ‰]
        I --> M[ã‚¹ã‚¯ãƒ©ãƒ ãƒã‚¹ã‚¿ãƒ¼]
        I --> N[ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼]
    end
    
    C --> I
    D --> I
    E --> I
    F --> I
```

#### 1.1.2 ã‚·ã‚¹ãƒ†ãƒ æ§‹æˆå›³

```mermaid
graph TB
    subgraph "å¤–éƒ¨ã‚µãƒ¼ãƒ“ã‚¹"
        LLM1[OpenAI API]
        LLM2[Anthropic API]
        LLM3[Other LLM APIs]
    end
    
    subgraph "PMPL Agent System"
        subgraph "ã‚³ã‚¢å±¤"
            COORD[ãƒ¡ã‚¤ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒãƒ¼ã‚¿ãƒ¼]
            REPORT[ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ]
        end
        
        subgraph "ãƒšãƒ«ã‚½ãƒŠå±¤"
            P1[ITã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—PM]
            P2[ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚ºPM]
            P3[ãƒ†ãƒƒã‚¯ãƒªãƒ¼ãƒ‰]
            P4[ã‚¹ã‚¯ãƒ©ãƒ ãƒã‚¹ã‚¿ãƒ¼]
            P5[ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼]
        end
        
        subgraph "ãƒ‡ãƒ¼ã‚¿å±¤"
            DB[(è­°è«–ãƒ‡ãƒ¼ã‚¿)]
            CONFIG[è¨­å®šç®¡ç†]
            STORAGE[ãƒ­ãƒ¼ã‚«ãƒ«ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸]
        end
        
        subgraph "ç®¡ç†å±¤"
            LLM_MGR[LLMãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼]
            CLI[CLI ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹]
        end
    end
    
    USER[ãƒ¦ãƒ¼ã‚¶ãƒ¼] --> CLI
    CLI --> COORD
    COORD --> P1
    COORD --> P2
    COORD --> P3
    COORD --> P4
    COORD --> P5
    COORD --> REPORT
    REPORT --> STORAGE
    LLM_MGR --> LLM1
    LLM_MGR --> LLM2
    LLM_MGR --> LLM3
    COORD --> LLM_MGR
    P1 --> LLM_MGR
    P2 --> LLM_MGR
    P3 --> LLM_MGR
    P4 --> LLM_MGR
    P5 --> LLM_MGR
    STORAGE --> DB
```

### 1.2 ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆéšå±¤æ§‹é€ 

#### 1.2.1 Strands Agentså®Ÿè£…æ§‹é€ 

```python
# åŸºæœ¬æ§‹é€ ï¼ˆç–‘ä¼¼ã‚³ãƒ¼ãƒ‰ï¼‰
class PMPLAgentSystem:
    def __init__(self):
        self.coordinator = MainCoordinator()
        self.sufficiency_judge = SufficiencyJudge()
        self.persona_agents = PersonaAgentFactory()
        self.analyzer = IssueAnalyzer()
        self.solver = SolutionGenerator()
        self.llm_manager = LLMManager()
    
    async def run_discussion(self, topic: str) -> DiscussionReport:
        # è­°è«–å®Ÿè¡Œãƒ¡ã‚¤ãƒ³ãƒ•ãƒ­ãƒ¼
        pass
```

## 2. è©³ç´°è¨­è¨ˆ

### 2.1 ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè¨­è¨ˆ

#### 2.1.1 ãƒ¡ã‚¤ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒãƒ¼ã‚¿ãƒ¼ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ

```python
from strands import Agent, tool
from typing import List, Dict, Any

COORDINATOR_SYSTEM_PROMPT = """
ã‚ãªãŸã¯è¤‡æ•°ã®ãƒšãƒ«ã‚½ãƒŠã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«ã‚ˆã‚‹è­°è«–ã‚’ãƒ•ã‚¡ã‚·ãƒªãƒ†ãƒ¼ãƒˆã™ã‚‹ãƒ¡ã‚¤ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒãƒ¼ã‚¿ãƒ¼ã§ã™ã€‚

è²¬å‹™:
1. è­°è«–ãƒ†ãƒ¼ãƒã®è«–ç‚¹ã‚’æ•´ç†ã—ã€ç„¦ç‚¹ã‚’æ˜ç¢ºåŒ–ã™ã‚‹
2. ãƒšãƒ«ã‚½ãƒŠé–“ã®å¯¾è©±ã‚’ä¿ƒé€²ã—ã€å»ºè¨­çš„ãªè­°è«–ã‚’èª˜å°ã™ã‚‹
3. æ„è¦‹ã®ç›¸é•ç‚¹ã‚’æ˜ç¢ºåŒ–ã—ã€æ·±æ˜ã‚Šã™ã¹ãè«–ç‚¹ã‚’ç‰¹å®šã™ã‚‹
4. æœ€çµ‚çš„ãªåˆæ„å½¢æˆã¨çµ±åˆã•ã‚ŒãŸè¦‹è§£ã®ä½œæˆã‚’æ”¯æ´ã™ã‚‹
5. è­°è«–å…¨ä½“ã®ç·ã¾ã¨ã‚ã¨ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼ã®ä½œæˆ

è­°è«–ãƒ•ãƒ­ãƒ¼:
ãƒ•ã‚§ãƒ¼ã‚º1: åˆæœŸè¦‹è§£è¡¨æ˜ï¼ˆå„ãƒšãƒ«ã‚½ãƒŠã®å°‚é–€çš„è¦–ç‚¹ã‹ã‚‰èª²é¡Œåˆ†æï¼‰
ãƒ•ã‚§ãƒ¼ã‚º2-3: ç›¸äº’è­°è«–ï¼ˆç„¦ç‚¹è«–ç‚¹ã«åŸºã¥ãå¯¾è©±çš„è­°è«–ï¼‰
ãƒ•ã‚§ãƒ¼ã‚º4: åˆæ„å½¢æˆï¼ˆçµ±åˆçš„ãªè¦‹è§£ã¨å®Ÿè¡Œå¯èƒ½ãªè§£æ±ºç­–ã®æç¤ºï¼‰
ãƒ•ã‚§ãƒ¼ã‚º5: ç·ã¾ã¨ã‚ï¼ˆPMPLãŒæ´»ç”¨ã§ãã‚‹å½¢ã§ã®çµ±åˆãƒ¬ãƒãƒ¼ãƒˆä½œæˆï¼‰

äººæãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆã¨ãƒ—ãƒ­ã‚»ã‚¹æ”¹å–„ã®å®Ÿè·µçš„è§£æ±ºç­–ã‚’ç›®æŒ‡ã—ã¦ãã ã•ã„ã€‚
"""

class MainCoordinator:
    def __init__(self, llm_manager: LLMManager):
        self.llm = llm_manager.get_llm("coordinator")
        self.persona_factory = PersonaAgentFactory()
    
    async def start_discussion(self, session: DiscussionSession, llm_manager: LLMManager) -> DiscussionRound:
        """å¯¾è©±çš„è­°è«–ã‚’é–‹å§‹"""
        basic_personas = self.persona_factory.get_basic_personas()
        discussion_round = session.add_round(basic_personas)
        
        await self._conduct_interactive_discussion(
            discussion_round, session.topic, session.organization_context, llm_manager
        )
        
        return discussion_round
    
    async def _conduct_interactive_discussion(self, discussion_round, topic, context, llm_manager):
        """5ãƒ•ã‚§ãƒ¼ã‚ºã®å¯¾è©±çš„è­°è«–ã‚’å®Ÿæ–½"""
        # ãƒ•ã‚§ãƒ¼ã‚º1: è«–ç‚¹æ•´ç†ã¨åˆæœŸè¦‹è§£
        await self._set_discussion_agenda(topic, context)
        await self._initial_statements_round(discussion_round, topic, context, llm_manager)
        
        # ãƒ•ã‚§ãƒ¼ã‚º2-3: ç›¸äº’è­°è«–ãƒ©ã‚¦ãƒ³ãƒ‰
        for round_num in range(2, 4):
            await self._interactive_discussion_round(discussion_round, topic, context, llm_manager, round_num)
        
        # ãƒ•ã‚§ãƒ¼ã‚º4: åˆæ„å½¢æˆ
        await self._consensus_building_round(discussion_round, topic, context, llm_manager)
        
        # ãƒ•ã‚§ãƒ¼ã‚º5: è­°è«–ç·ã¾ã¨ã‚
        await self._generate_discussion_summary(discussion_round, topic, context)
```

#### 2.1.2 ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ 

ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã¯ä»¥ä¸‹ã®æ§‹é€ ã§å®Ÿè£…ã•ã‚Œã¦ã„ã¾ã™ï¼š

1. **ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼**: ã‚³ãƒ¼ãƒ‡ã‚£ãƒãƒ¼ã‚¿ãƒ¼ã«ã‚ˆã‚‹è­°è«–ç·ã¾ã¨ã‚ã‚’æœ€ä¸Šä½ã«é…ç½®
2. **å‚åŠ è€…æƒ…å ±**: ãƒšãƒ«ã‚½ãƒŠãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã®è¡¨å½¢å¼è¡¨ç¤º
3. **è­°è«–æ¦‚è¦**: çµ±è¨ˆæƒ…å ±ã¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹
4. **ãƒ•ã‚§ãƒ¼ã‚ºåˆ¥è­°è«–è©³ç´°**: 5ãƒ•ã‚§ãƒ¼ã‚ºã®è©³ç´°ãªè­°è«–ãƒ­ã‚°
5. **ã‚³ãƒ¼ãƒ‡ã‚£ãƒãƒ¼ã‚¿ãƒ¼é€²è¡Œã‚¬ã‚¤ãƒ€ãƒ³ã‚¹**: å„ãƒ•ã‚§ãƒ¼ã‚ºã§ã®é€²è¡Œèª¬æ˜

ãƒ¬ãƒãƒ¼ãƒˆã¯ `reports/` ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«å‡ºåŠ›ã•ã‚Œã€Markdownå½¢å¼ã§æ§‹é€ åŒ–ã•ã‚Œã¾ã™ã€‚

```python
def _generate_simple_report(self, session: DiscussionSession) -> str:
    """ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã®ä¸»è¦æ©Ÿèƒ½"""
    # 1. ã‚³ãƒ¼ãƒ‡ã‚£ãƒãƒ¼ã‚¿ãƒ¼ç·ã¾ã¨ã‚ã‚’å–å¾—
    coordinator_summary = self._extract_coordinator_summary(session)
    
    # 2. ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼ã¨ã—ã¦é…ç½®
    if coordinator_summary:
        report_lines.extend([
            "## ğŸ¯ ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼",
            "*ãƒ¡ã‚¤ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒãƒ¼ã‚¿ãƒ¼ã«ã‚ˆã‚‹è­°è«–ç·ã¾ã¨ã‚*",
            coordinator_summary
        ])
    
    # 3. å‚åŠ è€…æƒ…å ±ã€è­°è«–è©³ç´°ã€ãƒ•ã‚§ãƒ¼ã‚ºåˆ¥åˆ†æã‚’è¿½åŠ 
    # ...
```

### 2.2 ãƒšãƒ«ã‚½ãƒŠã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè¨­è¨ˆ

#### 2.2.1 åŸºæœ¬ãƒšãƒ«ã‚½ãƒŠä»•æ§˜

```python
class PersonaAgent:
    def __init__(self, persona_config: PersonaConfig, llm_manager: LLMManager):
        self.config = persona_config
        self.agent = Agent(
            system_prompt=persona_config.system_prompt,
            tools=persona_config.tools,
            llm=llm_manager.get_llm(persona_config.llm_config)
        )
    
    async def discuss(self, topic: str, context: str) -> DiscussionOutput:
        """è­°è«–ã¸ã®å‚åŠ ã¨è¦‹è§£ã®æç¤º"""
        pass

@dataclass
class PersonaConfig:
    name: str
    role: str
    experience_years: int
    organization_type: str
    expertise_areas: List[str]
    system_prompt: str
    tools: List[callable]
    llm_config: str
```

#### 2.2.2 å…·ä½“çš„ãƒšãƒ«ã‚½ãƒŠå®šç¾©

```python
# ITã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—PMãƒšãƒ«ã‚½ãƒŠ
STARTUP_PM_PROMPT = """
ã‚ãªãŸã¯3-5å¹´ã®çµŒé¨“ã‚’æŒã¤ITã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—ã®ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã§ã™ã€‚

**èƒŒæ™¯**:
- 20-30äººè¦æ¨¡ã®æ€¥æˆé•·ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—ã§å‹¤å‹™
- é™ã‚‰ã‚ŒãŸãƒªã‚½ãƒ¼ã‚¹ã§æœ€å¤§ã®æˆæœã‚’æ±‚ã‚ã‚‰ã‚Œã‚‹ç’°å¢ƒ
- ã‚¹ãƒ”ãƒ¼ãƒ‰é‡è¦–ã€å®Œç’§æ€§ã‚ˆã‚Šã‚‚ç´ æ—©ã„æ„æ€æ±ºå®šã‚’é‡è¦–
- æŠ€è¡“è€…å‡ºèº«ã§ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã¨ã®å”æ¥­ã«é•·ã‘ã¦ã„ã‚‹

**å°‚é–€é ˜åŸŸ**:
- ãƒªã‚½ãƒ¼ã‚¹åˆ¶ç´„ä¸‹ã§ã®å„ªå…ˆé †ä½ä»˜ã‘
- é«˜é€Ÿãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ”ãƒ³ã‚°ã¨ä»®èª¬æ¤œè¨¼
- å°è¦æ¨¡ãƒãƒ¼ãƒ ã§ã®åŠ¹ç‡çš„ãªé–‹ç™ºãƒ—ãƒ­ã‚»ã‚¹
- æŠ€è¡“çš„è² å‚µã¨ã®ãƒãƒ©ãƒ³ã‚¹

**èª²é¡Œã«å¯¾ã™ã‚‹è¦–ç‚¹**:
- ã€Œã¾ãšã¯ã‚„ã£ã¦ã¿ã‚‹ã€ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ
- ROIï¼ˆæŠ•è³‡å¯¾åŠ¹æœï¼‰ã‚’å¸¸ã«æ„è­˜
- ãƒãƒ¼ãƒ å…¨å“¡ã®å½“äº‹è€…æ„è­˜ã‚’é‡è¦–
- ãƒ—ãƒ­ã‚»ã‚¹ã‚ˆã‚Šã‚‚æˆæœã‚’é‡è¦–

äººæãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆã¨ãƒ—ãƒ­ã‚»ã‚¹æ”¹å–„ã«ã¤ã„ã¦ã€ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—ç‰¹æœ‰ã®åˆ¶ç´„ã¨èª²é¡Œã®è¦³ç‚¹ã‹ã‚‰å…·ä½“çš„ãªè¦‹è§£ã‚’è¿°ã¹ã¦ãã ã•ã„ã€‚
"""

# ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚ºPMãƒšãƒ«ã‚½ãƒŠ  
ENTERPRISE_PM_PROMPT = """
ã‚ãªãŸã¯8-12å¹´ã®çµŒé¨“ã‚’æŒã¤å¤§ä¼æ¥­ã®ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã§ã™ã€‚

**èƒŒæ™¯**:
- 500äººä»¥ä¸Šã®å¤§è¦æ¨¡ITä¼æ¥­ã§å‹¤å‹™
- è¤‡æ•°éƒ¨é–€ã¨ã®èª¿æ•´ã¨æ‰¿èªãƒ—ãƒ­ã‚»ã‚¹ãŒå¿…è¦ãªç’°å¢ƒ
- å“è³ªãƒ»ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ»ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹ã‚’é‡è¦–
- é•·æœŸçš„ãªæˆ¦ç•¥ã¨æŒç¶šå¯èƒ½æ€§ã‚’é‡è¦–

**å°‚é–€é ˜åŸŸ**:
- æ¨™æº–åŒ–ã•ã‚ŒãŸãƒ—ãƒ­ã‚»ã‚¹ã®æ§‹ç¯‰ã¨é‹ç”¨
- ãƒªã‚¹ã‚¯ç®¡ç†ã¨å“è³ªä¿è¨¼
- ã‚¹ãƒ†ãƒ¼ã‚¯ãƒ›ãƒ«ãƒ€ãƒ¼ç®¡ç†
- ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆåŒ–ã¨çŸ¥è­˜å…±æœ‰

**èª²é¡Œã«å¯¾ã™ã‚‹è¦–ç‚¹**:
- ãƒ—ãƒ­ã‚»ã‚¹ã®æ¨™æº–åŒ–ã¨å†ç¾æ€§
- ãƒªã‚¹ã‚¯ã‚¢ã‚»ã‚¹ãƒ¡ãƒ³ãƒˆã¨äº‹å‰å¯¾ç­–
- é•·æœŸçš„ãªçµ„ç¹”èƒ½åŠ›å‘ä¸Š
- æ•™è‚²ãƒ»ç ”ä¿®ä½“ç³»ã®æ•´å‚™

10-50äººè¦æ¨¡çµ„ç¹”ãŒç›´é¢ã™ã‚‹ã€Œä¼æ¥­åŒ–ã€éç¨‹ã§ã®èª²é¡Œã«ã¤ã„ã¦ã€ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚ºã®çŸ¥è¦‹ã‚’æ´»ã‹ã—ãŸè¦‹è§£ã‚’è¿°ã¹ã¦ãã ã•ã„ã€‚
"""
```

### 2.3 LLMç®¡ç†ã‚·ã‚¹ãƒ†ãƒ 

#### 2.3.1 LLMãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼è¨­è¨ˆ

```python
from abc import ABC, abstractmethod
from enum import Enum
from dataclasses import dataclass
from typing import Optional, Dict, Any

class LLMProvider(Enum):
    OPENAI = "openai"
    ANTHROPIC = "anthropic"
    
class LLMModel(Enum):
    # OpenAI
    GPT_4O = "gpt-4o"
    GPT_4O_MINI = "gpt-4o-mini"
    GPT_35_TURBO = "gpt-3.5-turbo"
    
    # Anthropic
    CLAUDE_SONNET = "claude-3-sonnet-20240229"
    CLAUDE_HAIKU = "claude-3-haiku-20240307"

@dataclass
class LLMConfig:
    provider: LLMProvider
    model: LLMModel
    temperature: float = 0.7
    max_tokens: Optional[int] = None
    timeout: int = 30
    retry_count: int = 3

class LLMManager:
    def __init__(self, default_config: LLMConfig):
        self.default_config = default_config
        self.agent_configs: Dict[str, LLMConfig] = {}
        self.providers: Dict[LLMProvider, LLMProviderInterface] = {}
        
        # ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã®åˆæœŸåŒ–
        self._init_providers()
    
    def _init_providers(self):
        """LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã®åˆæœŸåŒ–"""
        self.providers[LLMProvider.OPENAI] = OpenAIProvider()
        self.providers[LLMProvider.ANTHROPIC] = AnthropicProvider()
    
    def set_agent_config(self, agent_name: str, config: LLMConfig):
        """ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåˆ¥LLMè¨­å®š"""
        self.agent_configs[agent_name] = config
    
    def get_llm(self, agent_name: str) -> LLMInterface:
        """ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆç”¨LLMã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹å–å¾—"""
        config = self.agent_configs.get(agent_name, self.default_config)
        provider = self.providers[config.provider]
        return provider.create_llm(config)

class LLMProviderInterface(ABC):
    @abstractmethod
    def create_llm(self, config: LLMConfig) -> LLMInterface:
        pass

class OpenAIProvider(LLMProviderInterface):
    def create_llm(self, config: LLMConfig) -> LLMInterface:
        # OpenAI LLMã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆ
        pass

class AnthropicProvider(LLMProviderInterface):  
    def create_llm(self, config: LLMConfig) -> LLMInterface:
        # Anthropic LLMã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆ
        pass
```

### 2.4 ãƒ‡ãƒ¼ã‚¿è¨­è¨ˆ

#### 2.4.1 è­°è«–ãƒ‡ãƒ¼ã‚¿æ§‹é€ 

```python
from datetime import datetime
from typing import List, Optional, Dict, Any
from pydantic import BaseModel, Field
from enum import Enum

class DiscussionStatus(Enum):
    INITIALIZED = "initialized"
    ROUND1_IN_PROGRESS = "round1_in_progress"
    JUDGING = "judging"
    ROUND2_IN_PROGRESS = "round2_in_progress"
    ANALYZING = "analyzing"
    COMPLETED = "completed"
    FAILED = "failed"

class IssueCategory(Enum):
    TALENT_MANAGEMENT = "talent_management"
    PROCESS_IMPROVEMENT = "process_improvement"
    ORGANIZATIONAL_SCALING = "organizational_scaling"

class IssuePriority(Enum):
    HIGH = "high"
    MEDIUM = "medium"
    LOW = "low"

class PersonaStatement(BaseModel):
    persona_name: str
    persona_role: str
    statement: str
    identified_issues: List[str]
    proposed_solutions: List[str]
    timestamp: datetime
    llm_model: str

class DiscussionRound(BaseModel):
    round_id: int
    participants: List[str]
    statements: List[PersonaStatement]
    identified_issues: List[str]
    started_at: datetime
    completed_at: Optional[datetime] = None

class SufficiencyJudgment(BaseModel):
    overall_score: float = Field(ge=0, le=100)
    coverage_analysis: Dict[str, float]  # ã‚«ãƒ†ã‚´ãƒªåˆ¥ã‚«ãƒãƒ¬ãƒƒã‚¸ã‚¹ã‚³ã‚¢
    missing_areas: List[str]
    recommended_personas: List[str]
    reasoning: str
    needs_additional_round: bool

class IdentifiedIssue(BaseModel):
    id: str
    title: str
    description: str
    category: IssueCategory
    priority: IssuePriority
    root_causes: List[str]
    affected_areas: List[str]
    mentioned_by: List[str]  # è¨€åŠã—ãŸãƒšãƒ«ã‚½ãƒŠ

class ProposedSolution(BaseModel):
    id: str
    issue_id: str
    title: str
    description: str
    implementation_steps: List[str]
    required_resources: List[str]
    timeline: str
    risks: List[str]
    expected_outcomes: List[str]

class DiscussionSession(BaseModel):
    session_id: str
    topic: str
    organization_context: Dict[str, Any]
    status: DiscussionStatus
    rounds: List[DiscussionRound]
    sufficiency_judgments: List[SufficiencyJudgment]
    final_issues: List[IdentifiedIssue]
    final_solutions: List[ProposedSolution]
    created_at: datetime
    updated_at: datetime
    completed_at: Optional[datetime] = None
    
    class Config:
        json_encoders = {
            datetime: lambda v: v.isoformat()
        }
```

### 2.5 ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ 

#### 2.5.1 Markdownãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå™¨

```python
from jinja2 import Template
from typing import Dict, Any

class ReportGenerator:
    def __init__(self):
        self.template = self._load_template()
    
    def generate_report(self, session: DiscussionSession) -> str:
        """è­°è«–ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‹ã‚‰Markdownãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        context = self._prepare_context(session)
        return self.template.render(**context)
    
    def _load_template(self) -> Template:
        template_str = """
# PMPLèª²é¡Œåˆ†æãƒ¬ãƒãƒ¼ãƒˆ

**ç”Ÿæˆæ—¥æ™‚**: {{ generated_at }}  
**ã‚»ãƒƒã‚·ãƒ§ãƒ³ID**: {{ session_id }}  
**è­°è«–ãƒ†ãƒ¼ãƒ**: {{ topic }}

## ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼

### è­°è«–å‚åŠ è€…
{% for round in rounds %}
**ãƒ©ã‚¦ãƒ³ãƒ‰{{ round.round_id }}**:
{% for participant in round.participants %}
- {{ participant }}
{% endfor %}
{% endfor %}

### ä¸»è¦èª²é¡Œ ({{ issues|length }}é …ç›®)
{% for issue in priority_issues[:5] %}
{{ loop.index }}. **{{ issue.title }}** ({{ issue.priority.value|upper }})
   - {{ issue.description }}
{% endfor %}

## èª²é¡Œè©³ç´°åˆ†æ

### äººæãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆèª²é¡Œ
{% for issue in talent_issues %}
#### {{ issue.title }} 
**å„ªå…ˆåº¦**: {{ issue.priority.value|upper }}

**èª²é¡Œè©³ç´°**:
{{ issue.description }}

**æ ¹æœ¬åŸå› **:
{% for cause in issue.root_causes %}
- {{ cause }}
{% endfor %}

**å½±éŸ¿ç¯„å›²**:
{% for area in issue.affected_areas %}
- {{ area }}
{% endfor %}

**è¨€åŠè€…**: {{ issue.mentioned_by|join(', ') }}

---
{% endfor %}

### ãƒ—ãƒ­ã‚»ã‚¹æ”¹å–„èª²é¡Œ
{% for issue in process_issues %}
#### {{ issue.title }}
**å„ªå…ˆåº¦**: {{ issue.priority.value|upper }}

**èª²é¡Œè©³ç´°**:
{{ issue.description }}

**æ ¹æœ¬åŸå› **:
{% for cause in issue.root_causes %}
- {{ cause }}
{% endfor %}

**å½±éŸ¿ç¯„å›²**:
{% for area in issue.affected_areas %}
- {{ area }}
{% endfor %}

**è¨€åŠè€…**: {{ issue.mentioned_by|join(', ') }}

---
{% endfor %}

## è§£æ±ºç­–ææ¡ˆ

{% for solution in solutions %}
### {{ solution.title }}
**å¯¾è±¡èª²é¡Œ**: {{ solution.issue_id }}

**æ¦‚è¦**:
{{ solution.description }}

**å®Ÿè£…ã‚¹ãƒ†ãƒƒãƒ—**:
{% for step in solution.implementation_steps %}
{{ loop.index }}. {{ step }}
{% endfor %}

**å¿…è¦ãƒªã‚½ãƒ¼ã‚¹**:
{% for resource in solution.required_resources %}
- {{ resource }}
{% endfor %}

**å®Ÿè£…æœŸé–“**: {{ solution.timeline }}

**ãƒªã‚¹ã‚¯**:
{% for risk in solution.risks %}
- {{ risk }}
{% endfor %}

**æœŸå¾…åŠ¹æœ**:
{% for outcome in solution.expected_outcomes %}
- {{ outcome }}
{% endfor %}

---
{% endfor %}

## å®Ÿè£…ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—

### çŸ­æœŸæ–½ç­–ï¼ˆ1-3ãƒ¶æœˆï¼‰
{% for solution in short_term_solutions %}
- **{{ solution.title }}**: {{ solution.timeline }}
{% endfor %}

### ä¸­æœŸæ–½ç­–ï¼ˆ3-12ãƒ¶æœˆï¼‰
{% for solution in medium_term_solutions %}
- **{{ solution.title }}**: {{ solution.timeline }}
{% endfor %}

### é•·æœŸæ–½ç­–ï¼ˆ1å¹´ä»¥ä¸Šï¼‰
{% for solution in long_term_solutions %}
- **{{ solution.title }}**: {{ solution.timeline }}
{% endfor %}

## è­°è«–ãƒ­ã‚°ã‚µãƒãƒªãƒ¼

{% for round in rounds %}
### ãƒ©ã‚¦ãƒ³ãƒ‰{{ round.round_id }} ({{ round.started_at.strftime('%Y-%m-%d %H:%M') }})

{% for statement in round.statements %}
#### {{ statement.persona_name }}ã®è¦‹è§£
{{ statement.statement }}

**ç‰¹å®šã—ãŸèª²é¡Œ**:
{% for issue in statement.identified_issues %}
- {{ issue }}
{% endfor %}
{% endfor %}
{% endfor %}

## ååˆ†æ€§è©•ä¾¡

{% for judgment in sufficiency_judgments %}
**è©•ä¾¡ãƒ©ã‚¦ãƒ³ãƒ‰{{ loop.index }}**:
- **ç·åˆã‚¹ã‚³ã‚¢**: {{ judgment.overall_score }}/100
- **è¿½åŠ è­°è«–è¦å¦**: {{ "å¿…è¦" if judgment.needs_additional_round else "ä¸è¦" }}

**é ˜åŸŸåˆ¥ã‚«ãƒãƒ¬ãƒƒã‚¸**:
{% for area, score in judgment.coverage_analysis.items() %}
- {{ area }}: {{ score }}/100
{% endfor %}

**è©•ä¾¡ç†ç”±**:
{{ judgment.reasoning }}
{% endfor %}
"""
        return Template(template_str)
```

## 3. APIè¨­è¨ˆ

### 3.1 ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆä»•æ§˜

```python
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from typing import Optional

app = FastAPI(title="PMPL Agent System API")

class DiscussionRequest(BaseModel):
    topic: str
    organization_context: Optional[Dict[str, Any]] = None
    llm_config: Optional[Dict[str, Any]] = None

class DiscussionResponse(BaseModel):
    session_id: str
    status: str
    message: str

@app.post("/discussions", response_model=DiscussionResponse)
async def start_discussion(request: DiscussionRequest):
    """æ–°ã—ã„è­°è«–ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’é–‹å§‹"""
    pass

@app.get("/discussions/{session_id}")
async def get_discussion_status(session_id: str):
    """è­°è«–ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®çŠ¶æ…‹ã‚’å–å¾—"""
    pass

@app.get("/discussions/{session_id}/report")
async def get_discussion_report(session_id: str):
    """è­°è«–ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ãƒ¬ãƒãƒ¼ãƒˆã‚’å–å¾—"""
    pass

@app.post("/discussions/{session_id}/configure-llm")
async def configure_llm(session_id: str, config: Dict[str, Any]):
    """ã‚»ãƒƒã‚·ãƒ§ãƒ³å˜ä½ã§LLMè¨­å®šã‚’å¤‰æ›´"""
    pass
```

## 4. è¨­å®šç®¡ç†

### 4.1 ç’°å¢ƒè¨­å®š

```yaml
# config/default.yaml
system:
  default_llm:
    provider: "openai"
    model: "gpt-4o"
    temperature: 0.7
    max_tokens: 2000
    
agents:
  coordinator:
    llm:
      provider: "openai"
      model: "gpt-4o"
      temperature: 0.3
  
  judge:
    llm:
      provider: "openai"
      model: "gpt-4o"
      temperature: 0.1
      
  personas:
    startup_pm:
      llm:
        provider: "openai"
        model: "gpt-4o-mini"
        temperature: 0.8
    
discussion:
  max_rounds: 3
  sufficiency_threshold: 75.0
  timeout_minutes: 30

storage:
  type: "local"  # "local" or "database"
  path: "./data/discussions"
```

## 5. å®Ÿè£…å„ªå…ˆé †ä½

### Phase 1: åŸºæœ¬æ©Ÿèƒ½ (3é€±é–“)
1. LLMãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼å®Ÿè£…
2. åŸºæœ¬ãƒšãƒ«ã‚½ãƒŠã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ5ä½“å®Ÿè£…
3. ã‚·ãƒ³ãƒ—ãƒ«ãªè­°è«–ãƒ•ãƒ­ãƒ¼å®Ÿè£…
4. åŸºæœ¬çš„ãªãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ

### Phase 2: é«˜åº¦ãªæ©Ÿèƒ½ (2é€±é–“)  
1. èª²é¡Œååˆ†æ€§åˆ¤å®šã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®Ÿè£…
2. å‹•çš„ãƒšãƒ«ã‚½ãƒŠé¸å®šæ©Ÿèƒ½
3. è©³ç´°ãªãƒ‡ãƒ¼ã‚¿æ§‹é€ å®Ÿè£…

### Phase 3: å“è³ªå‘ä¸Š (2é€±é–“)
1. ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å¼·åŒ–
2. ãƒ­ã‚°ãƒ»ç›£è¦–æ©Ÿèƒ½å®Ÿè£…
3. ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸å‘ä¸Š
4. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–

### Phase 4: é‹ç”¨æº–å‚™ (1é€±é–“)
1. DockeråŒ–
2. CI/CDè¨­å®š
3. ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•´å‚™
4. ãƒ‡ãƒ¢ãƒ»ã‚µãƒ³ãƒ—ãƒ«ä½œæˆ 